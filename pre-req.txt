1. Make sure to download Ollama to your machine from https://ollama.com/download/OllamaSetup.exe
2. You need to check that ollama is actually running, so try in windows 10 (ms-dos prompt or powershell)
   curl 127.0.0.1:11434
   You should get a "ollama is running" message
3. Install all the relevant embedding models, such as the below ( these can be found in the https://ollama.com/library 
     ollama pull nomic-embed-text
     ollama run llama3.2
4. If you are running the app as streamlit, run it as streamlit run your_script.py

5. If you want to download a model from hugging face, make sure to select a GGUF file from hugging face  similar to https://huggingface.co/arcee-ai/SuperNova-Medius-GGUF, copy it, and on the terminal type in 
	ollama run hf.co/arcee-ai/SuperNova-Medius-GGUF
	this will download the model to your local store